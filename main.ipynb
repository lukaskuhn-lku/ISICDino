{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from torchvision.models import vit_b_16\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, ToPILImage\n",
    "\n",
    "from utils import fix_random_seeds, clip_gradients, compute_knn_accuracy\n",
    "from dataset import ISICDataset\n",
    "from dino import DataAugmentationDINO, MultiCropWrapper, DINOHead, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('data/metadata.csv')\n",
    "labels = metadata['malignant'].values.astype(int)\n",
    "files = [f\"data/ISIC_2024_Training_Input/{f}\" for f in os.listdir('data/ISIC_2024_Training_Input') if f.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = DataAugmentationDINO(global_crops_scale=(0.4, 1.0), local_crops_scale=(0.05, 0.4), local_crops_number=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_size = 10000\n",
    "\n",
    "norm_only = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "dataset_train = ISICDataset(files, labels, transform=transform)\n",
    "dataset_knn = ISICDataset(files, labels, transform=norm_only)\n",
    "\n",
    "targets = torch.tensor(labels)\n",
    "# get all indices where targets is 1\n",
    "positive_indices = torch.where(targets == 1)[0]\n",
    "\n",
    "# get 10.000 random indices where targets is 0\n",
    "negative_indices = torch.where(targets == 0)[0]\n",
    "negative_indices_train = negative_indices[torch.randperm(negative_indices.size(0))[:total_train_size-len(positive_indices)]]\n",
    "\n",
    "# combine positive and negative indices\n",
    "indices = torch.cat([positive_indices, negative_indices_train])\n",
    "\n",
    "train_dataset = Subset(dataset_train, indices)\n",
    "\n",
    "# get 50% of the positive indices\n",
    "positive_indices_knn_val = positive_indices[torch.randperm(positive_indices.size(0))[:len(positive_indices)//2]]\n",
    "\n",
    "# fill up to 1000 indices with negative indices\n",
    "negative_indices_knn_val = negative_indices[torch.randperm(negative_indices.size(0))[:1000-len(positive_indices_knn_val)]]\n",
    "\n",
    "knn_val_dataset = Subset(dataset_knn, torch.cat([positive_indices_knn_val, negative_indices_knn_val]))\n",
    "\n",
    "# get the rest of the positive indices\n",
    "positive_indices_knn_train = positive_indices[torch.randperm(positive_indices.size(0))[len(positive_indices)//2:]]\n",
    "\n",
    "# fill up to 5000 indices with negative indices\n",
    "negative_indices_knn_train = negative_indices[torch.randperm(negative_indices.size(0))[1000-len(positive_indices_knn_val):(5000-len(positive_indices_knn_train))+(1000-len(positive_indices_knn_val))]]\n",
    "\n",
    "knn_train_dataset = Subset(dataset_knn, torch.cat([positive_indices_knn_train, negative_indices_knn_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukaskuhn/Documents/Code/ISICDino/venv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "student = vit_b_16(weights=None)\n",
    "teacher = vit_b_16(weights=None)\n",
    "\n",
    "# make teacher and student have the same weights\n",
    "teacher.load_state_dict(student.state_dict())\n",
    "\n",
    "student = MultiCropWrapper(student, DINOHead(768, 1024))\n",
    "teacher = MultiCropWrapper(teacher, DINOHead(768, 1024))\n",
    "\n",
    "student = student.to(device)\n",
    "teacher = teacher.to(device)\n",
    "\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dino_loss = DINOLoss(1024,8+2,0.04,0.04,0,100)\n",
    "dino_loss = Loss(1024)\n",
    "dino_loss = dino_loss.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0005 * 16 / 256\n",
    "optimizer = torch.optim.AdamW(student.parameters(), lr=lr, weight_decay=1e-6)\n",
    "momentum_teacher = 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_number = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5000 [00:02<2:47:21,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating KNN accuracy for report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 155/313 [01:01<01:02,  2.53it/s]\n",
      "  0%|          | 1/5000 [01:04<89:57:04, 64.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (num_batches \u001b[38;5;241m%\u001b[39m log_number) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating KNN accuracy for report\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m     acc, preds, train_lbls, val_lbls \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_knn_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknn_train_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknn_val_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKNN Accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Code/ISICDino/utils.py:78\u001b[0m, in \u001b[0;36mcompute_knn_accuracy\u001b[0;34m(backbone, knn_train_dataset, knn_val_dataset, device, k)\u001b[0m\n\u001b[1;32m     76\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     77\u001b[0m     features \u001b[38;5;241m=\u001b[39m backbone(images)\n\u001b[0;32m---> 78\u001b[0m     train_features\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[1;32m     79\u001b[0m     train_labels\u001b[38;5;241m.\u001b[39mappend(labels)\n\u001b[1;32m     81\u001b[0m train_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(train_features, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for e in range(epochs):\n",
    "    num_batches = 0\n",
    "    for images, _ in tqdm(dataset_loader):\n",
    "        images = [img.to(device) for img in images]\n",
    "        student_output = student(images)\n",
    "        teacher_output = teacher(images[:2])\n",
    "\n",
    "        loss = dino_loss(student_output, teacher_output)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_gradients(student)\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for student_ps, teacher_ps in zip(\n",
    "                student.parameters(), teacher.parameters()\n",
    "            ):\n",
    "                teacher_ps.data.mul_(momentum_teacher)\n",
    "                teacher_ps.data.add_(\n",
    "                    (1 - momentum_teacher) * student_ps.detach().data\n",
    "                )\n",
    "\n",
    "        num_batches += 1\n",
    "\n",
    "        if (num_batches % log_number) == 0:\n",
    "            print(f\"Calculating KNN accuracy for report\")\n",
    "            acc, preds, train_lbls, val_lbls = compute_knn_accuracy(student.backbone, knn_train_dataset, knn_val_dataset, device, 64)\n",
    "            print(f\"KNN Accuracy {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
