{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.models import vit_b_16\n",
    "\n",
    "from utils import fix_random_seeds, clip_gradients, compute_knn_accuracy\n",
    "from dataset import ISICDataset, get_random_subset_without_given_indices\n",
    "from dino import DataAugmentationDINO, MultiCropWrapper, DINOHead, DINOLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_random_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('data/metadata.csv')\n",
    "labels = metadata['malignant'].values.astype(int)\n",
    "files = [f\"data/ISIC24/{f}\" for f in os.listdir('data/ISIC24')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = DataAugmentationDINO(global_crops_scale=(0.4, 1.0), local_crops_scale=(0.05, 0.4), local_crops_number=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ISICDataset(files, labels, transform=transform)\n",
    "dataset_loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class counts\n",
    "from torch.utils.data import WeightedRandomSampler, Subset\n",
    "\n",
    "targets = torch.tensor(dataset.labels)\n",
    "class_counts = torch.bincount(targets)\n",
    "num_zeros = class_counts[0].item()\n",
    "num_ones = class_counts[1].item()\n",
    "\n",
    "# Create weight tensor\n",
    "weights = torch.ones(len(targets))\n",
    "weights[targets == 1] = num_zeros / num_ones\n",
    "\n",
    "sampler = WeightedRandomSampler(weights, 500, replacement=False)\n",
    "\n",
    "# sample all the indices via the weighted sampler\n",
    "indices = list(sampler)\n",
    "\n",
    "sampler = WeightedRandomSampler(weights, 1000, replacement=False)\n",
    "indices_train = list(sampler)\n",
    "\n",
    "# remove from train indices the indices that are in the validation indices\n",
    "indices_train = [idx for idx in indices_train if idx not in indices]\n",
    "\n",
    "# get the subset of the dataset\n",
    "val_knn_subset = Subset(dataset, indices)\n",
    "\n",
    "# get the remaining indices\n",
    "train_knn_subset = Subset(dataset, indices_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = vit_b_16(weights=None)\n",
    "teacher = vit_b_16(weights=None)\n",
    "\n",
    "# make teacher and student have the same weights\n",
    "teacher.load_state_dict(student.state_dict())\n",
    "\n",
    "student = MultiCropWrapper(student, DINOHead(768, 1024))\n",
    "teacher = MultiCropWrapper(teacher, DINOHead(768, 1024))\n",
    "\n",
    "student = student.to(device)\n",
    "teacher = teacher.to(device)\n",
    "\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dino_loss = DINOLoss(1024,8+2,0.04,0.04,0,100)\n",
    "dino_loss = dino_loss.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0005 * 16 / 256\n",
    "optimizer = torch.optim.AdamW(student.parameters(), lr=lr, weight_decay=1e-6)\n",
    "momentum_teacher = 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_number = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "for e in range(epochs):\n",
    "    num_batches = 0\n",
    "    for images, _ in tqdm(dataset_loader):\n",
    "        images = [img.to(device) for img in images]\n",
    "        student_output = student(images)\n",
    "        teacher_output = teacher(images[:2])\n",
    "\n",
    "        loss = dino_loss(student_output, teacher_output, e)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_gradients(student)\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for student_ps, teacher_ps in zip(\n",
    "                student.parameters(), teacher.parameters()\n",
    "            ):\n",
    "                teacher_ps.data.mul_(momentum_teacher)\n",
    "                teacher_ps.data.add_(\n",
    "                    (1 - momentum_teacher) * student_ps.detach().data\n",
    "                )\n",
    "\n",
    "        num_batches += 1\n",
    "\n",
    "        if (num_batches % log_number) == 0:\n",
    "            print(f\"Calculating KNN accuracy for report\")\n",
    "            acc, preds, train_lbls, val_lbls = compute_knn_accuracy(student.backbone, train_knn_subset, val_knn_subset, device, 64)\n",
    "            print(f\"KNN Accuracy {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
